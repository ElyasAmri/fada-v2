{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedGemma 4B VQA Pipeline Test\n",
    "\n",
    "**Model**: `google/medgemma-4b-it`  \n",
    "**Task**: Medical Visual Question Answering on Fetal Ultrasound Images  \n",
    "**Status**: ❌ FAILED - Gated model requires HuggingFace authentication\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook documents an attempt to test Google's MedGemma 4B instruction-tuned model for medical visual question answering on fetal ultrasound images. MedGemma is a specialized medical LLM that could potentially provide detailed analysis of ultrasound images.\n",
    "\n",
    "**Note**: This is a research prototype test only. NOT for clinical use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATA_DIR = Path(r\"C:\\Users\\elyas\\Workspace\\PyCharm\\fada-v3\\data\\Fetal Ultrasound Labeled\")\n",
    "IMAGE_DIR = Path(r\"C:\\Users\\elyas\\Workspace\\PyCharm\\fada-v3\\data\\Fetal Ultrasound\\Non_standard_NT\")\n",
    "\n",
    "# Load annotations\n",
    "excel_path = DATA_DIR / \"Non_standard_NT_image_list.xlsx\"\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare VQA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract question columns\n",
    "q_cols = [col for col in df.columns if col.startswith('Q')]\n",
    "print(f\"Questions per image: {len(q_cols)}\")\n",
    "\n",
    "# Build VQA dataset from first 5 images\n",
    "vqa_data = []\n",
    "for idx, row in df.head(5).iterrows():\n",
    "    img_path = IMAGE_DIR / row['Image Name']\n",
    "    if not img_path.exists():\n",
    "        continue\n",
    "    \n",
    "    for q_col in q_cols:\n",
    "        question = q_col.split('\\n', 1)[1] if '\\n' in q_col else q_col\n",
    "        question = question[:100]\n",
    "        answer = str(row[q_col])\n",
    "        \n",
    "        if pd.notna(answer) and answer.lower() not in ['nan', 'none', '']:\n",
    "            vqa_data.append({\n",
    "                'image_path': str(img_path),\n",
    "                'question': question,\n",
    "                'answer': answer\n",
    "            })\n",
    "\n",
    "print(f\"Prepared {len(vqa_data)} VQA examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = Image.open(vqa_data[0]['image_path']).convert('RGB')\n",
    "print(f\"Image loaded: {test_img.size}\")\n",
    "test_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Loading Attempt\n",
    "\n",
    "**NOTE: This cell will FAIL with authentication error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/medgemma-4b-it\"\n",
    "\n",
    "try:\n",
    "    print(f\"Attempting to load model: {model_id}\")\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    print(\"Processor loaded successfully\")\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    print(\"Model loaded successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ ERROR: {type(e).__name__}\")\n",
    "    print(f\"Error message: {str(e)}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FAILURE ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nMedGemma is a GATED MODEL that requires:\")\n",
    "    print(\"  1. HuggingFace account authentication\")\n",
    "    print(\"  2. Acceptance of model terms of use\")\n",
    "    print(\"  3. Potential Google approval process\")\n",
    "    print(\"\\nTo access this model:\")\n",
    "    print(\"  1. Visit: https://huggingface.co/google/medgemma-4b-it\")\n",
    "    print(\"  2. Accept the license agreement\")\n",
    "    print(\"  3. Generate HF token: https://huggingface.co/settings/tokens\")\n",
    "    print(\"  4. Login via CLI: huggingface-cli login\")\n",
    "    print(\"  5. Wait for approval (may take time)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Test Result: ❌ FAILED\n",
    "\n",
    "**Reason**: MedGemma 4B is a gated model requiring HuggingFace authentication and Google approval.\n",
    "\n",
    "### Error Details\n",
    "- **Error Type**: `GatedRepoError`\n",
    "- **HTTP Status**: 401 Client Error\n",
    "- **Root Cause**: Cannot access gated repository without proper credentials\n",
    "\n",
    "### Why This Test Was Skipped\n",
    "\n",
    "1. **Authentication Complexity**: Requires HuggingFace account setup and token generation\n",
    "2. **Approval Process**: May require Google's approval to access the model\n",
    "3. **Time Constraints**: Project timeline doesn't allow waiting for gated model approval\n",
    "4. **Alternative Options**: Other open VLMs available that don't require special access\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **For this project**: Continue with open models (BLIP-2, Florence-2, LLaVA)\n",
    "2. **Future work**: If VQA is needed, try LLaVA-Med or BLIP-2 first\n",
    "3. **If MedGemma is essential**: Budget time for authentication and approval process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
