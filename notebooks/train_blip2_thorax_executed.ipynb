{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {
    "papermill": {
     "duration": 0.001118,
     "end_time": "2025-10-02T00:29:41.547885",
     "exception": false,
     "start_time": "2025-10-02T00:29:41.546767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BLIP-2 Medical VQA Training - Thorax (1 Epoch Validation)\n",
    "\n",
    "Train BLIP-2 on fetal ultrasound thorax images Q&A for 1 epoch to validate pipeline.\n",
    "\n",
    "**Model**: Salesforce/blip2-opt-2.7b (8-bit)\n",
    "**Data**: 5 images, 40 Q&A pairs, split 3/1/1\n",
    "**Training time**: ~10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T00:29:41.552398Z",
     "iopub.status.busy": "2025-10-02T00:29:41.551396Z",
     "iopub.status.idle": "2025-10-02T00:29:41.562750Z",
     "shell.execute_reply": "2025-10-02T00:29:41.562419Z"
    },
    "papermill": {
     "duration": 0.013364,
     "end_time": "2025-10-02T00:29:41.563253",
     "exception": false,
     "start_time": "2025-10-02T00:29:41.549889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters (can be overridden by papermill)\n",
    "num_images = 5\n",
    "num_epochs = 1\n",
    "batch_size = 1\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T00:29:41.567258Z",
     "iopub.status.busy": "2025-10-02T00:29:41.566257Z",
     "iopub.status.idle": "2025-10-02T00:29:48.173409Z",
     "shell.execute_reply": "2025-10-02T00:29:48.173409Z"
    },
    "papermill": {
     "duration": 6.609152,
     "end_time": "2025-10-02T00:29:48.174409",
     "exception": false,
     "start_time": "2025-10-02T00:29:41.565257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration, TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T00:29:48.177916Z",
     "iopub.status.busy": "2025-10-02T00:29:48.177916Z",
     "iopub.status.idle": "2025-10-02T00:29:48.188497Z",
     "shell.execute_reply": "2025-10-02T00:29:48.188497Z"
    },
    "papermill": {
     "duration": 0.013088,
     "end_time": "2025-10-02T00:29:48.188497",
     "exception": false,
     "start_time": "2025-10-02T00:29:48.175409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: C:\\Users\\elyas\\Workspace\\PyCharm\\fada-v3\\outputs\\blip2_thorax\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "BASE = Path(r\"C:\\Users\\elyas\\Workspace\\PyCharm\\fada-v3\")\n",
    "DATA_DIR = BASE / \"data/Fetal Ultrasound Labeled\"\n",
    "IMAGE_DIR = BASE / \"data/Fetal Ultrasound/Thorax\"\n",
    "OUTPUT_DIR = BASE / \"outputs/blip2_thorax\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"Salesforce/blip2-opt-2.7b\"\n",
    "print(f\"Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T00:29:48.193026Z",
     "iopub.status.busy": "2025-10-02T00:29:48.192026Z",
     "iopub.status.idle": "2025-10-02T00:29:48.409040Z",
     "shell.execute_reply": "2025-10-02T00:29:48.409040Z"
    },
    "papermill": {
     "duration": 0.219016,
     "end_time": "2025-10-02T00:29:48.410041",
     "exception": false,
     "start_time": "2025-10-02T00:29:48.191025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 28, Val: 6, Test: 6\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_excel(DATA_DIR / \"Thorax_image_list.xlsx\")\n",
    "q_cols = [c for c in df.columns if c.startswith('Q')]\n",
    "\n",
    "vqa_data = []\n",
    "for _, row in df.head(num_images).iterrows():\n",
    "    img_path = IMAGE_DIR / row['Image Name']\n",
    "    if not img_path.exists():\n",
    "        continue\n",
    "    for q_col in q_cols:\n",
    "        q = q_col.split('\\n', 1)[1][:100] if '\\n' in q_col else q_col[:100]\n",
    "        a = str(row[q_col])\n",
    "        if pd.notna(a) and a.lower() not in ['nan', 'none', '']:\n",
    "            vqa_data.append({'image_path': str(img_path), 'question': q, 'answer': a})\n",
    "\n",
    "# Split: 70% train, 15% val, 15% test\n",
    "n_train = int(len(vqa_data) * 0.7)\n",
    "n_val = int(len(vqa_data) * 0.15)\n",
    "train_data = vqa_data[:n_train]\n",
    "val_data = vqa_data[n_train:n_train+n_val]\n",
    "test_data = vqa_data[n_train+n_val:]\n",
    "\n",
    "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T00:29:48.415040Z",
     "iopub.status.busy": "2025-10-02T00:29:48.414042Z",
     "iopub.status.idle": "2025-10-02T00:30:09.584047Z",
     "shell.execute_reply": "2025-10-02T00:30:09.584047Z"
    },
    "papermill": {
     "duration": 21.173007,
     "end_time": "2025-10-02T00:30:09.585048",
     "exception": false,
     "start_time": "2025-10-02T00:29:48.412041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d023679be40e4653a371fa696f8b556a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,621,440 || all params: 3,747,383,296 || trainable%: 0.0700\n",
      "Memory: 4.48 GB\n"
     ]
    }
   ],
   "source": [
    "# Load model with LoRA\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "processor = Blip2Processor.from_pretrained(MODEL_NAME)\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Prepare for training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Add LoRA adapters\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "print(f\"Memory: {model.get_memory_footprint() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T00:30:09.590559Z",
     "iopub.status.busy": "2025-10-02T00:30:09.589553Z",
     "iopub.status.idle": "2025-10-02T00:30:09.600065Z",
     "shell.execute_reply": "2025-10-02T00:30:09.600065Z"
    },
    "papermill": {
     "duration": 0.013102,
     "end_time": "2025-10-02T00:30:09.601151",
     "exception": false,
     "start_time": "2025-10-02T00:30:09.588049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets ready: 28 train, 6 val\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "class VQADataset(Dataset):\n",
    "    def __init__(self, data, processor):\n",
    "        self.data = data\n",
    "        self.processor = processor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = Image.open(item['image_path']).convert('RGB')\n",
    "        prompt = f\"Question: {item['question']} Answer:\"\n",
    "        \n",
    "        inputs = self.processor(\n",
    "            images=img,\n",
    "            text=prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            max_length=256,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        labels = self.processor.tokenizer(\n",
    "            item['answer'],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            truncation=True\n",
    "        )[\"input_ids\"]\n",
    "        \n",
    "        return {\n",
    "            'pixel_values': inputs['pixel_values'].squeeze(),\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'labels': labels.squeeze()\n",
    "        }\n",
    "\n",
    "train_dataset = VQADataset(train_data, processor)\n",
    "val_dataset = VQADataset(val_data, processor)\n",
    "print(f\"Datasets ready: {len(train_dataset)} train, {len(val_dataset)} val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T00:30:09.605152Z",
     "iopub.status.busy": "2025-10-02T00:30:09.605152Z",
     "iopub.status.idle": "2025-10-02T00:30:09.694756Z",
     "shell.execute_reply": "2025-10-02T00:30:09.694756Z"
    },
    "papermill": {
     "duration": 0.092537,
     "end_time": "2025-10-02T00:30:09.695688",
     "exception": false,
     "start_time": "2025-10-02T00:30:09.603151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer ready\n"
     ]
    }
   ],
   "source": [
    "# Training config\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(OUTPUT_DIR),\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    logging_steps=5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "print(\"Trainer ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T00:30:09.700199Z",
     "iopub.status.busy": "2025-10-02T00:30:09.700199Z",
     "iopub.status.idle": "2025-10-02T00:30:33.685633Z",
     "shell.execute_reply": "2025-10-02T00:30:33.684774Z"
    },
    "papermill": {
     "duration": 23.987438,
     "end_time": "2025-10-02T00:30:33.685633",
     "exception": false,
     "start_time": "2025-10-02T00:30:09.698195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyas\\Workspace\\PyCharm\\fada-v3\\venv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\elyas\\Workspace\\PyCharm\\fada-v3\\venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "C:\\Users\\elyas\\Workspace\\PyCharm\\fada-v3\\venv\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.345200</td>\n",
       "      <td>4.245099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n",
      "Time: 0.39 minutes\n",
      "Final loss: 5.2833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\elyas\\Workspace\\PyCharm\\fada-v3\\outputs\\blip2_thorax\\final_model\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "start_time = time.time()\n",
    "train_result = trainer.train()\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Time: {training_time/60:.2f} minutes\")\n",
    "print(f\"Final loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "# Save\n",
    "trainer.save_model(str(OUTPUT_DIR / \"final_model\"))\n",
    "processor.save_pretrained(str(OUTPUT_DIR / \"final_model\"))\n",
    "print(f\"Model saved to {OUTPUT_DIR / 'final_model'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T00:30:33.691152Z",
     "iopub.status.busy": "2025-10-02T00:30:33.691152Z",
     "iopub.status.idle": "2025-10-02T00:30:35.816239Z",
     "shell.execute_reply": "2025-10-02T00:30:35.816239Z"
    },
    "papermill": {
     "duration": 2.128602,
     "end_time": "2025-10-02T00:30:35.817241",
     "exception": false,
     "start_time": "2025-10-02T00:30:33.688639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyas\\Workspace\\PyCharm\\fada-v3\\venv\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:186: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Inference:\n",
      "Q: Plane Evaluation: Assess if the image is taken at a standard diagnostic plane and describe its diagn\n",
      "Predicted: Question: Plane Evaluation: Assess if the image is taken at a standard diagnostic plane and describe its diagn Answer: The image is taken at a standard diagnostic plane and describes the patient's anatomy\n",
      "\n",
      "Ground truth: Yes  the image is taken at a standard diagnostic plane, four chambers are visualized\n"
     ]
    }
   ],
   "source": [
    "# Test inference\n",
    "model.eval()\n",
    "test_item = test_data[0]\n",
    "test_img = Image.open(test_item['image_path']).convert('RGB')\n",
    "test_prompt = f\"Question: {test_item['question']} Answer:\"\n",
    "\n",
    "inputs = processor(images=test_img, text=test_prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "    prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "print(f\"\\nTest Inference:\")\n",
    "print(f\"Q: {test_item['question']}\")\n",
    "print(f\"Predicted: {prediction}\")\n",
    "print(f\"Ground truth: {test_item['answer'][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T00:30:35.822743Z",
     "iopub.status.busy": "2025-10-02T00:30:35.822743Z",
     "iopub.status.idle": "2025-10-02T00:30:35.831779Z",
     "shell.execute_reply": "2025-10-02T00:30:35.831779Z"
    },
    "papermill": {
     "duration": 0.01354,
     "end_time": "2025-10-02T00:30:35.832780",
     "exception": false,
     "start_time": "2025-10-02T00:30:35.819240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING SUMMARY\n",
      "============================================================\n",
      "model: Salesforce/blip2-opt-2.7b\n",
      "category: Thorax\n",
      "num_images: 5\n",
      "train_samples: 28\n",
      "val_samples: 6\n",
      "test_samples: 6\n",
      "epochs: 1\n",
      "training_time_min: 0.38789313634236655\n",
      "final_loss: 5.283334527696882\n",
      "output_dir: C:\\Users\\elyas\\Workspace\\PyCharm\\fada-v3\\outputs\\blip2_thorax\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "summary = {\n",
    "    'model': MODEL_NAME,\n",
    "    'category': 'Thorax',\n",
    "    'num_images': num_images,\n",
    "    'train_samples': len(train_data),\n",
    "    'val_samples': len(val_data),\n",
    "    'test_samples': len(test_data),\n",
    "    'epochs': num_epochs,\n",
    "    'training_time_min': training_time/60,\n",
    "    'final_loss': train_result.training_loss,\n",
    "    'output_dir': str(OUTPUT_DIR)\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(OUTPUT_DIR / 'training_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 56.997938,
   "end_time": "2025-10-02T00:30:36.812523",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/train_blip2_thorax.ipynb",
   "output_path": "notebooks/train_blip2_thorax_executed.ipynb",
   "parameters": {},
   "start_time": "2025-10-02T00:29:39.814585",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1b41e28fa82b46a6ba75cc850b3725c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_84d16d99e6ec4e769c041f304fe18b79",
       "placeholder": "​",
       "style": "IPY_MODEL_d7105d300f1540f687aec2915d9da2b4",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "4f4d7d28bf4948b6b194eb065c86549a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "740e840bf8384836b5084381b37d6d54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4f4d7d28bf4948b6b194eb065c86549a",
       "placeholder": "​",
       "style": "IPY_MODEL_d8c909458f0b4e5fb4b7dfd19c067021",
       "tabbable": null,
       "tooltip": null,
       "value": " 2/2 [00:14&lt;00:00,  6.53s/it]"
      }
     },
     "84d16d99e6ec4e769c041f304fe18b79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9976c67304304f56aa561c678700a9d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e51610c0832a4ac59dd64cf87a01b18b",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cfa0f127e4b145e7be7b9c63fef4bab2",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "c4f3bc9ec2f94fa3ae5399199e396e2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfa0f127e4b145e7be7b9c63fef4bab2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d023679be40e4653a371fa696f8b556a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1b41e28fa82b46a6ba75cc850b3725c9",
        "IPY_MODEL_9976c67304304f56aa561c678700a9d0",
        "IPY_MODEL_740e840bf8384836b5084381b37d6d54"
       ],
       "layout": "IPY_MODEL_c4f3bc9ec2f94fa3ae5399199e396e2d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d7105d300f1540f687aec2915d9da2b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d8c909458f0b4e5fb4b7dfd19c067021": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e51610c0832a4ac59dd64cf87a01b18b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}