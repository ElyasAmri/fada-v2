# VLM Testing Documentation

**Project**: FADA (Fetal Anomaly Detection Algorithm)
**Testing Period**: October 1-3, 2025
**Total Models Tested**: 50+
**Champion Model**: MiniCPM-V-2.6 (88.9% accuracy)

---

## Current Documentation (October 2025)

### Primary Documents

1. **[complete_vlm_testing_results.md](complete_vlm_testing_results.md)** â­ **MAIN REFERENCE**
   - Comprehensive results from all 50+ models tested
   - Detailed performance metrics and analysis
   - Top-5 performers with full specifications
   - Recommendations for production deployment
   - **Start here** for complete technical details

2. **[all_models_tested.md](all_models_tested.md)** ğŸ“‹ **MASTER LIST**
   - Complete list of all 55+ unique models tested
   - Organized by testing phase (Comprehensive, Legacy, Quick Tests)
   - Models grouped by family (OpenBMB, Qwen, InternVL, LLaVA, etc.)
   - Success/failure breakdown with reasons
   - Hardware and quantization notes

3. **[vlm_testing_complete.md](vlm_testing_complete.md)** ğŸ“Š **SUMMARY**
   - Concise overview of testing results
   - Key findings and recommendations
   - Testing statistics and conclusion

---

## Quick Reference

### Top 5 Models (Production-Ready)

| Rank | Model | Accuracy | Memory | Best For |
|------|-------|----------|--------|----------|
| ğŸ¥‡ 1 | **MiniCPM-V-2.6** | 88.9% | ~5GB | **Production deployment** |
| ğŸ¥ˆ 2 | **Qwen2-VL-2B** | 83.3% | ~4GB | Efficiency/speed |
| ğŸ¥‰ 3 | **InternVL2-4B** | ~82% | ~5GB | Medical understanding |
| 4 | **InternVL2-2B** | ~80% | ~3.5GB | Resource-constrained |
| 5 | **LLaVA-OneVision** | ~80% | ~6GB | General-purpose VLM |

### Recommendation

**Use MiniCPM-V-2.6 for FADA production deployment**
- 88.9% zero-shot accuracy on fetal ultrasound VQA
- 61% improvement over initial baseline (BLIP-2 at 55%)
- Excellent fetal context and anatomy understanding
- Efficient with 4-bit quantization (~5GB VRAM)
- Latest 2024 architecture with strong transfer learning

**Next Step**: Fine-tune MiniCPM-V-2.6 on full FADA dataset (target: 95%+ accuracy)

---

## Testing Phases

### Phase 1: Quick Tests
- **Models**: 16 test scripts
- **Purpose**: Rapid initial screening
- **Result**: Identified BLIP-2 baseline (~55%)

### Phase 2: Legacy Tests
- **Models**: 24 test scripts
- **Purpose**: Comprehensive older model evaluation
- **Result**: Quantization critical, many 2023 models underperform

### Phase 3: Comprehensive Tests
- **Models**: 13 test scripts
- **Purpose**: Latest 2024-2025 model evaluation
- **Result**: Modern models vastly superior (80%+ achievable)
- **Champion**: MiniCPM-V-2.6 at 88.9%

---

## Key Findings

1. **Modern Models Dominate**: Latest 2024-2025 models (MiniCPM, Qwen2-VL, InternVL2) significantly outperform 2023 models
2. **Small Can Be Powerful**: 2B models (Qwen2-VL-2B) achieve 83.3% accuracy
3. **Quantization Works**: 4-bit quantization enables 7-8B models on 8GB VRAM with minimal accuracy loss
4. **Medical-Specific â‰  Universal**: Medical models trained on X-rays (CheXagent) fail on ultrasound
5. **BLIP-2 Obsolete**: 2023 baseline (55%) surpassed by 61% with modern architectures

---

## Archived Documentation

Historical documents (pre-October 3, 2025) moved to `archive/`:
- `alternative_vlms.md` - Early model alternatives (outdated: recommends TinyGPT-V, BLIP-2)
- `vlm_comparison.md` - Initial comparisons (outdated: BLIP-2 as best)
- `vlm_models_remaining.md` - Models to test list (outdated: testing complete)
- `vlm_models_to_test.md` - Testing plan (outdated: testing complete)
- `smolvlm_test_results.md` - SmolVLM specific results (consolidated)
- `vlm_test_results.md` - Early test results (outdated: incomplete)

**Note**: Archived documents contain outdated recommendations (BLIP-2 as best model). Refer to current documentation for accurate information.

---

## File Organization

```
docs/experiments/vlm/
â”œâ”€â”€ README.md                              # This file
â”œâ”€â”€ complete_vlm_testing_results.md        # â­ Main reference (21KB)
â”œâ”€â”€ all_models_tested.md                   # ğŸ“‹ Master list (11KB)
â”œâ”€â”€ vlm_testing_complete.md                # ğŸ“Š Summary (6.5KB)
â””â”€â”€ archive/                               # Outdated documents
    â”œâ”€â”€ alternative_vlms.md
    â”œâ”€â”€ vlm_comparison.md
    â”œâ”€â”€ vlm_models_remaining.md
    â”œâ”€â”€ vlm_models_to_test.md
    â”œâ”€â”€ smolvlm_test_results.md
    â””â”€â”€ vlm_test_results.md
```

---

## Statistics

- **Total Models Tested**: 50+
- **Successfully Loaded**: 40+
- **Failed**: 10+
- **Testing Duration**: ~1 week
- **Test Scripts Created**: 53
- **Best Performance**: 88.9% (MiniCPM-V-2.6)
- **Baseline Performance**: 55% (BLIP-2)
- **Improvement**: 61%

---

## Related Documentation

- **VQA Training**: `docs/experiments/vqa/vqa_training_summary.md`
- **Integration Testing**: `docs/experiments/integration/`
- **Project Specs**: `docs/project/spec.md`

---

*Last Updated: October 3, 2025*
*Champion: MiniCPM-V-2.6 at 88.9%*
*Status: Testing Complete, Production Ready*
